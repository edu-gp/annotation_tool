steps:
# Build the alchemy test image
#
- name: 'gcr.io/cloud-builders/docker'
  args: ['build',
         '--target', 'test',
         '--tag', 'gcr.io/$PROJECT_ID/alchemy:test-${SHORT_SHA}',
         '.']
  id: 'build-test-image'

# Run the tests, to prevent having broken
# images. May look unnecessary since there are
# GitHub actions that run tests, however it
# wouldn't hurt to double check.
#
- name: 'gcr.io/cloud-builders/docker'
  args: ['run',
         '--env', 'GOOGLE_AI_PLATFORM_ENABLED=0',
         '--env', 'USE_CLOUD_LOGGING=0',
         '--entrypoint', 'ci/run_tests.sh',
         'gcr.io/$PROJECT_ID/alchemy:test-${SHORT_SHA}']
  wait_for: ['build-test-image']
  id: 'run-tests'

# Build the target image (if target != test)
#
- name: 'gcr.io/cloud-builders/docker'
  entrypoint: "bash"
  args:
    - "-c"
    - |
       if [ "${_TARGET}" != "test" ]; then
        docker build \
            --target ${_TARGET} \
            --cache-from gcr.io/$PROJECT_ID/alchemy:test-${SHORT_SHA} \
            --tag gcr.io/$PROJECT_ID/alchemy:${_TARGET}-${SHORT_SHA} \
            .
        else
          echo Skipped rebuilding the test image
        fi
  wait_for: ['run-tests']
  id: 'build-target-image'

# Tag the target as latest in case it is a production image
#
- name: 'gcr.io/cloud-builders/docker'
  entrypoint: "bash"
  args:
    - "-c"
    - |
        if [ "${_TARGET}" = "production" ]; then
          echo Tagging production image as latest
          docker tag gcr.io/$PROJECT_ID/alchemy:${_TARGET}-${SHORT_SHA} gcr.io/$PROJECT_ID/alchemy:latest
          echo Pushing gcr.io/$PROJECT_ID/alchemy:latest
          docker push gcr.io/$PROJECT_ID/alchemy:latest
        else
          echo Not production target, not tagging as latest.
        fi
  id: 'tag-latest'
  wait_for: ['build-target-image']

# Deploy in production. This step can be skipped in case _NO_DEPLOY
# substitution is set (to anything).
#
- name: 'gcr.io/cloud-builders/gcloud'
  entrypoint: "bash"
  args:
    - "-c"
    - |
      if [ "${_TARGET}" = "production" ] && [ -z ${_NO_DEPLOY} ]; then
        #INSTANCES=$(gcloud compute instances list --filter="name=cpu-gather-labels")
        #echo INSTANCES = $INSTANCES
        echo Downloading the keys
        gcloud secrets versions access latest --secret=alchemy-builder-ssh > id_rsa
        gcloud secrets versions access latest --secret=alchemy-builder-ssh-pub > id_rsa.pub
        echo "" >> id_rsa ; echo "" >> id_rsa.pub ;  # Add a new line to the end

        # INSTANCES=$(gcloud compute instances list --filter="${_DEPLOY_FILTER}")
        echo Copying the keys
        gcloud compute ssh \
            --zone "us-central1-a" \
            --project "nlp-flywheel" \
            "${_DEPLOY_MACHINE}" -- "mkdir -p ~/.ssh/"
        gcloud compute scp \
            --zone "us-central1-a" \
            --project "nlp-flywheel" \
            id_rsa* ${_DEPLOY_MACHINE}:~/.ssh/

        echo "Updating the project"
        gcloud compute ssh \
            --zone "us-central1-a" \
            --project "nlp-flywheel" \
            "${_DEPLOY_MACHINE}" -- " \
              chmod 600 ~/.ssh/id_rsa
              chmod 644 ~/.ssh/id_rsa.pub
              cd /var/www
              git pull
              docker pull gcr.io/nlp-flywheel/alchemy:latest && \
              docker-compose -f docker-compose-staging.yml down && \
              docker-compose -f docker-compose-staging.yml up -d
              rm -rf ~/.ssh/"
      else
        echo "Not going to deploy"
      fi
timeout: 1200s
images:
  - 'gcr.io/$PROJECT_ID/alchemy:${_TARGET}-${SHORT_SHA}'
